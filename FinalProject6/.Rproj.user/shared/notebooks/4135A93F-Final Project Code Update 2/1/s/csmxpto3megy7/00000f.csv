"0","confusion_metrics <- function(beta, x, y) {"
"0","  # Calculate predicted probabilities"
"0","  p <- 1 / (1 + exp(-x %*% beta))"
"0","  "
"0","  # Convert probabilities to binary predictions using a cutoff of 0.5"
"0","  y_pred <- ifelse(p > 0.5, 1, 0)"
"0","  "
"0","  # Create confusion matrix"
"0","  tp <- sum(y_pred == 1 & y == 1)"
"0","  tn <- sum(y_pred == 0 & y == 0)"
"0","  fp <- sum(y_pred == 1 & y == 0)"
"0","  fn <- sum(y_pred == 0 & y == 1)"
"0","  "
"0","  confusion_matrix <- matrix(c(tp, fp, fn, tn), nrow = 2, byrow = TRUE)"
"0","  rownames(confusion_matrix) <- c(""Predicted 1"", ""Predicted 0"")"
"0","  colnames(confusion_matrix) <- c(""Actual 1"", ""Actual 0"")"
"0","  "
"0","  # Calculate metrics"
"0","  prevalence <- (tp + fn) / (tp + tn + fp + fn)"
"0","  accuracy <- (tp + tn) / (tp + tn + fp + fn)"
"0","  sensitivity <- tp / (tp + fn)"
"0","  specificity <- tn / (tn + fp)"
"0","  false_discovery_rate <- fp / (tp + fp)"
"0","  diagnostic_odds_ratio <- (tp / fn) / (fp / tn)"
"0","  "
"0","  metrics <- list("
"0","    Prevalence = prevalence,"
"0","    Accuracy = accuracy,"
"0","    Sensitivity = sensitivity,"
"0","    Specificity = specificity,"
"0","    FalseDiscoveryRate = false_discovery_rate,"
"0","    DiagnosticOddsRatio = diagnostic_odds_ratio"
"0","  )"
"0","  "
"0","  return(list(ConfusionMatrix = confusion_matrix, Metrics = metrics))"
"0","}"
"0",""
