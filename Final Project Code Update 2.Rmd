---
title: "R Notebook"
output: html_notebook
---
# Functions to be used by main function

1. Format input from user for use in future functions
```{r}
format_input <- function(x, y, data){
  # check user input
  ## generate an appropriate error if the corresponding column names not found or if data is not a data frame
  # Check if data is a data frame
  if (!is.data.frame(data)) {stop("The input 'data' must be a data frame.")}
  if(!y %in% colnames(data)){stop(paste("The y column of interest,", y, "was not found in the data frame of interest. Please double check the name of the column you are interested in and try again!"))}
  if(!all(x %in% colnames(data))){stop(paste("One of more of the x columns you are interested in was not found in the data frame of interest."))}
  
  ## extract x and y columns from the data frame
  y <- data[[y]]
  x <- data[ , x, drop = FALSE]
  
  ## format
  ## ensure y is treated as numeric, since using numerical optimization for binary classification
  ## ensure x is formatted to numeric with character / factors being converted to dummy variables
  y <- as.factor(y)
  y <- as.numeric(y) - 1
  x <- model.matrix(~ ., data = x)
  
  ## store current output in list
  list1 <- list(x = x, y = y)
  
  return(list1)
  
}
```

2. Define the initial guesses for beta using the least squares estimators
```{r}
# Determine Initial Beta Coefficients
  beta_initial_guess <- function(x, y, data){
    ## Format user data
    list1 <- format_input(x, y, data)
      x <- list1$x
      y <- list1$y
      xx <- t(x)%*%x
    
    # Check for singularity
    if (det(xx) == 0) stop("Matrix X'X is singular and cannot be inverted.")
    
    xx <- solve(xx)
    
    return(xx %*% t(x) %*% y)
    
    }
```

3. Define the loss function
```{r}
  # Loss function: Negative log-likelihood
  loss_function <- function(beta, x, y){
    
    p <- 1 / (1 + exp(-x %*% beta))
    
    # Check if any p is exactly 0 or 1, which would cause log(0) or log(1) errors
    
    if (any(p == 0 | p == 1)) {
      epsilon <- 1e-15
      p <- pmax(pmin(p, 1 - epsilon), epsilon)
      
      # Notify the user if epsilon was applied
      if (!epsilon_applied) {
        warning("Log(0) or Log(1) encountered. Epsilon was applied to probabilities to avoid numerical errors.")
        epsilon_applied <<- TRUE
        }
    }
    
    # Negative log-likelihood
    log_likelihood <- -sum(y * log(p) + (1 - y) * log(1 - p))
    
    return(log_likelihood)
  }
```


# find the optimal estimates for logistic regression

```{r}
logistic_regression <- function(x, y, data){
  
  list1 <- format_input(x = x, y = y, data = data)
  
  # Determine Initial Beta Coefficients
  beta_initial <- beta_initial_guess(x, y, data)
  
  # set initial epsilon_applied to FALSE for use in generating a warning if used in the loss function
  epsilon_applied <<- FALSE
  
  # estimate coefficients
  optimal_result <- optim(par = beta_initial,
                          fn = loss_function,
                          x = list1$x,
                          y = list1$y,
                          method = "BFGS")
  
  beta_estimate <- optimal_result$par
  
  # update list
    list2 <- list(Coefficient = colnames(list1$x), beta_initial = beta_initial,  beta_estimate = beta_estimate)
    my_output <- list(user_data = list1, coefficients = list2)
    
  # provide user with relevant output  
    return(my_output) 
    print(my_output$coefficients)
}
```    

```{r}
bootstrapping <- function(x, y, data, alpha = 0.05, B = 20) {
  
  ## Format user data
  list1 <- format_input(x, y, data)
    x <- list1$x
    y <- list1$y
  
    # Determine Initial Beta Coefficients
  beta_initial_guess2 <- function(x, y){
    xx <- t(x)%*%x
    # Check for singularity
    if (det(xx) == 0) stop("Matrix X'X is singular and cannot be inverted.")
    xx <- solve(xx)
    return(xx %*% t(x) %*% y)
        }
    
  ## Create matrices to store the results
  beta_bootstrap_estimates <- matrix(NA, nrow = B, ncol = ncol(x)) # Store optimized coefficients
  beta_bootstrap_initial <- matrix(NA, nrow = B, ncol = ncol(x))  # Store initial guesses
  n <- nrow(data)
  
  ## Perform bootstrapping
  for (i in 1:B) {
    # Resample data
    index <- sample(1:n, size = n, replace = TRUE)
    x_boot <- x[index, , drop = FALSE]
    y_boot <- y[index]
    
    # Calculate initial beta for resampled data
    beta_boot <- beta_initial_guess2(x = x_boot, y = y_boot)
    beta_bootstrap_initial[i, ] <- beta_boot
    
    # Optimize to find "optimal" beta
    boot_optim <- optim(par = beta_boot,
                        fn = loss_function,
                        x = x_boot,
                        y = y_boot,
                        method = "BFGS")
    beta_bootstrap_estimates[i, ] <- boot_optim$par
  }
  
  ## Compute Confidence Intervals (Percentile Method)
  lower_bound <- apply(beta_bootstrap_estimates, 2, function(est) quantile(est, probs = alpha / 2))
  upper_bound <- apply(beta_bootstrap_estimates, 2, function(est) quantile(est, probs = 1 - alpha / 2))
  estimate <- colMeans(beta_bootstrap_estimates) # Average bootstrap estimates
  
  ## Combine Results into Lists
  coefficients_mat <- rbind(
    Beta_Bootstrap_Estimates = beta_bootstrap_estimates,
    Beta_Bootstrap_Initial = beta_bootstrap_initial
  )
  colnames(coefficients_mat) <- colnames(x)
  
  confidence_intervals_mat<- rbind(
    Lower = lower_bound,
    Estimate = estimate,
    Upper = upper_bound
  )
  colnames(confidence_intervals_mat) <- colnames(x)
  
  ## Output
  result <- list(
    Coefficients = coefficients_mat,
    ConfidenceIntervals = confidence_intervals_mat
  )
  
  return(result)
}

```


    
    



```{r}
# example for testing output
adult <- read.csv("adult.csv", sep=";")
check1 <- format_input(x = c("age", "workclass", "hours.per.week"), y = "sex", data = adult)
check2 <- beta_initial_guess(x = c("age", "workclass", "hours.per.week"), y = "sex", data = adult)
check3 <- logistic_regression(x = c("age", "workclass", "hours.per.week"), y = "sex", data = adult)
check4 <- bootstrapping(x = c("age", "workclass", "hours.per.week"), y = "sex", data = adult)
```

```{r}
confusion_metrics <- function(beta, x, y) {
  # Calculate predicted probabilities
  p <- 1 / (1 + exp(-x %*% beta))
  
  # Convert probabilities to binary predictions using a cutoff of 0.5
  y_pred <- ifelse(p > 0.5, 1, 0)
  
  # Create confusion matrix
  tp <- sum(y_pred == 1 & y == 1)
  tn <- sum(y_pred == 0 & y == 0)
  fp <- sum(y_pred == 1 & y == 0)
  fn <- sum(y_pred == 0 & y == 1)
  
  confusion_matrix <- matrix(c(tp, fp, fn, tn), nrow = 2, byrow = TRUE)
  rownames(confusion_matrix) <- c("Predicted 1", "Predicted 0")
  colnames(confusion_matrix) <- c("Actual 1", "Actual 0")
  
  # Calculate metrics
  prevalence <- (tp + fn) / (tp + tn + fp + fn)
  accuracy <- (tp + tn) / (tp + tn + fp + fn)
  sensitivity <- tp / (tp + fn)
  specificity <- tn / (tn + fp)
  false_discovery_rate <- fp / (tp + fp)
  diagnostic_odds_ratio <- (tp / fn) / (fp / tn)
  
  metrics <- list(
    Prevalence = prevalence,
    Accuracy = accuracy,
    Sensitivity = sensitivity,
    Specificity = specificity,
    FalseDiscoveryRate = false_discovery_rate,
    DiagnosticOddsRatio = diagnostic_odds_ratio
  )
  
  return(list(ConfusionMatrix = confusion_matrix, Metrics = metrics))
}

```


```{r}
#' Perform Logistic Regression
#' @param x A character vector specifying the independent variables.
#' @param y A character string specifying the dependent variable.
#' @param data A data frame containing the variables.
#' @return A list containing the user data, initial beta estimates, and optimized beta estimates.
#' @export
logistic_regression

```


```{r}
# Example of testing confusion matrix and metrics
adult <- read.csv("adult.csv", sep = ";")
logistic_result <- logistic_regression(x = c("age", "workclass", "hours.per.week"), y = "sex", data = adult)
metrics_result <- confusion_metrics(beta = logistic_result$coefficients$beta_estimate, x = logistic_result$user_data$x, y = logistic_result$user_data$y)

# Print results
print(metrics_result$ConfusionMatrix)
print(metrics_result$Metrics)
```


